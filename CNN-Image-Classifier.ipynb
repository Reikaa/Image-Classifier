{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "\n",
    "from os.path                    import join, basename\n",
    "from scipy.misc                 import imresize, imread\n",
    "from datetime                   import datetime\n",
    "from keras.models               import Sequential\n",
    "from keras.layers               import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.pooling       import MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D, ZeroPadding2D\n",
    "from keras.optimizers           import Adam\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(model, X,  y):\n",
    "    \"Return the accuracy of model on Inputs X and labels y.\"\n",
    "    y_hat = model.predict_classes(X, verbose=0)\n",
    "    n_correct = (np.array(y_hat) == np.array(y)).sum()\n",
    "    return n_correct / float(y.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def prod(z):\n",
    "    \"Return the product z[0] * z[1] * ... * z[-1].\"\n",
    "    result = 1\n",
    "    for i in range(0, len(z)):\n",
    "        result *= z[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_course_images(directory, image_size):\n",
    "    labels = []\n",
    "    files  = [f for f in os.listdir(directory) if f.endswith(\"jpg\")]\n",
    "    shape  = [len(files)] + [image_size, image_size, 4]\n",
    "    X      = np.zeros(shape = shape) + np.nan  # Put a NaN in each cell to make sure we \n",
    "    \n",
    "    for imageIndex, f in enumerate(files):\n",
    "        I = imread(\"{}/{}\".format(directory, f))\n",
    "        I = imresize(I, [image_size, image_size])\n",
    "        X[imageIndex, :, :, 0:3] = I / 255.0                # rgb  channels\n",
    "        X[imageIndex, :, :, 3]   = (I.mean(axis=2) / 255.0) # gray channel\n",
    "        labels.append(f.split(\"_\")[0]) # Pull the LABEL out of the image name\n",
    "        \n",
    "    assert np.isnan(X).sum() == 0 # Make sure no NaNs remain in the data.\n",
    "    y        = np.array([LABELS.index(lbl) for lbl in labels]) # Collect all the LABELs.\n",
    "    y_onehot = np.zeros((X.shape[0], len(LABELS))) # Now need to convert to a 'one hot'\n",
    "    for rowIndex, colIndex in enumerate(y):  # This will produce ( (0, y(0)), (1, y\n",
    "        y_onehot[rowIndex, colIndex] = 1 # For each image, set one output unit to 1.  \n",
    "    return X, y, y_onehot, [join(directory, f) for f in files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_DIR           = \"/Users/gautam/IdeaProjects/Lab3DNN/images/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS            = ['airplanes', 'butterfly', 'flower', 'grand', 'starfish', 'watch']   \n",
    "imageDimension    = 32\n",
    "numberOfColors    =   4 # R, G, B, and Gray\n",
    "epochsToRun       = 100\n",
    "batch_size        =  10 # how many gradients we collect before updating weights\n",
    "platesConv1       =  16\n",
    "platesConv2       =  16\n",
    "kernelSizeConv1   =   4\n",
    "kernelSizePool1   =   2\n",
    "kernelSizeConv2   =   4\n",
    "kernelSizePool2   =   2\n",
    "strideConv1       =   1 # same for both x and y dimensions\n",
    "stridePool1       =   2 # same for both x and y dimensions\n",
    "strideConv2       =   1 # same for both x and y dimensions\n",
    "stridePool2       =   2 # same for both x and y dimensions\n",
    "zeroPaddingConv1  =   1 # same for both x and y dimensions (this is padding of the INPUT \n",
    "zeroPaddingPool1  =   1 # same for both x and y dimensions (this is padding of the CONV1\n",
    "zeroPaddingConv2  =   1 # same for both x and y dimensions (this is padding of the POOL1 \n",
    "zeroPaddingPool2  =   1 # same for both x and y dimensions (this is padding of the CONV2\n",
    "input_dropoutProb =   0.05\n",
    "conv1_dropoutProb =   0.50\n",
    "pool1_dropoutProb =   0.00\n",
    "conv2_dropoutProb =   0.50\n",
    "pool2_dropoutProb =   0.00\n",
    "final_dropoutProb =   0.50\n",
    "numberOfFinalHUs  = 128\n",
    "numberOfClasses   = len(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 554 training examples.\n",
      "There are 180 tuning examples.\n",
      "There are 178 testing examples.\n"
     ]
    }
   ],
   "source": [
    "confusionTestsetAtBestTuneset = np.zeros((numberOfClasses, numberOfClasses))\n",
    "bestTuneSetEpoch     = np.nan\n",
    "bestTuneSetAcc       = 0\n",
    "testSetAccAtBestTune = 0\n",
    "\n",
    "\n",
    "X_train, y_train, y_onehot_train, img_files_train = load_course_images(directory=\"{}/trainset\".format(IMG_DIR), image_size=imageDimension)\n",
    "X_tune,  y_tune,  y_onehot_tune,  img_files_tune  = load_course_images(directory=\"{}/tuneset\".format( IMG_DIR), image_size=imageDimension)\n",
    "X_test,  y_test,  y_onehot_test,  img_files_test  = load_course_images(directory=\"{}/testset\".format( IMG_DIR), image_size=imageDimension)\n",
    "print(\"There are {:,} training examples.\".format(len(X_train)))\n",
    "print(\"There are {:,} tuning examples.\".format(  len(X_tune)))\n",
    "print(\"There are {:,} testing examples.\".format( len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "leakyReLUtoUse = LeakyReLU(alpha = 0.1)\n",
    "model.add(Conv2D(platesConv1, kernel_size = kernelSizeConv1,\n",
    "                 input_shape = [imageDimension, imageDimension, numberOfColors],data_format = \"channels_last\", strides     = strideConv1, \n",
    "                 padding     = \"valid\", \n",
    "                 use_bias    = True))\n",
    "                 \n",
    "model.add(leakyReLUtoUse); \n",
    "model.add(ZeroPadding2D(padding = zeroPaddingConv1, data_format = \"channels_last\"))\n",
    "model.add(Dropout(conv1_dropoutProb)) \n",
    "\n",
    "model.add(MaxPooling2D(pool_size = kernelSizePool1, strides = stridePool1, padding = 'valid'))\n",
    "model.add(Dropout(pool1_dropoutProb))\n",
    "model.add(ZeroPadding2D(padding  = zeroPaddingPool1))\n",
    "\n",
    "model.add(Conv2D(platesConv2, \n",
    "                 kernel_size = kernelSizeConv2,\n",
    "                 strides     = strideConv2, \n",
    "                 padding     = \"valid\", \n",
    "                 use_bias    = True))\n",
    "model.add(leakyReLUtoUse); # Have to add as a layer, not as an argument to Conv2D.\n",
    "model.add(Dropout(conv2_dropoutProb))\n",
    "model.add(ZeroPadding2D(padding=  zeroPaddingConv2))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = kernelSizePool2, strides = stridePool2, padding = 'valid'))\n",
    "model.add(Dropout(pool2_dropoutProb))\n",
    "model.add(ZeroPadding2D(padding  = zeroPaddingPool2))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(units = numberOfFinalHUs))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(final_dropoutProb))\n",
    "\n",
    "model.add(Dense(units = numberOfClasses))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The model has 210,854 trainable weights.\n",
      "\n",
      "After    1 epochs, accuracies are:  train = 0.556  tune = 0.522* test = 0.562    06:49:57  04-01-2017\n",
      "After    2 epochs, accuracies are:  train = 0.605  tune = 0.600* test = 0.624    06:49:58  04-01-2017\n",
      "After    3 epochs, accuracies are:  train = 0.670  tune = 0.656* test = 0.646    06:50:00  04-01-2017\n",
      "After    4 epochs, accuracies are:  train = 0.776  tune = 0.683* test = 0.680    06:50:02  04-01-2017\n",
      "After    5 epochs, accuracies are:  train = 0.827  tune = 0.689* test = 0.713    06:50:04  04-01-2017\n",
      "After    6 epochs, accuracies are:  train = 0.877  tune = 0.750* test = 0.742    06:50:06  04-01-2017\n",
      "After    7 epochs, accuracies are:  train = 0.892  tune = 0.750  test = 0.742    06:50:09  04-01-2017\n",
      "After    8 epochs, accuracies are:  train = 0.910  tune = 0.761* test = 0.747    06:50:12  04-01-2017\n",
      "After    9 epochs, accuracies are:  train = 0.915  tune = 0.778* test = 0.764    06:50:14  04-01-2017\n",
      "After   10 epochs, accuracies are:  train = 0.930  tune = 0.772  test = 0.770    06:50:16  04-01-2017\n",
      "After   11 epochs, accuracies are:  train = 0.948  tune = 0.778  test = 0.792    06:50:19  04-01-2017\n",
      "After   12 epochs, accuracies are:  train = 0.922  tune = 0.733  test = 0.747    06:50:20  04-01-2017\n",
      "After   13 epochs, accuracies are:  train = 0.971  tune = 0.794* test = 0.803    06:50:22  04-01-2017\n",
      "After   14 epochs, accuracies are:  train = 0.962  tune = 0.767  test = 0.803    06:50:23  04-01-2017\n",
      "After   15 epochs, accuracies are:  train = 0.971  tune = 0.767  test = 0.775    06:50:25  04-01-2017\n",
      "After   16 epochs, accuracies are:  train = 0.977  tune = 0.794  test = 0.803    06:50:27  04-01-2017\n",
      "After   17 epochs, accuracies are:  train = 0.968  tune = 0.778  test = 0.826    06:50:29  04-01-2017\n",
      "After   18 epochs, accuracies are:  train = 0.986  tune = 0.806* test = 0.809    06:50:32  04-01-2017\n",
      "After   19 epochs, accuracies are:  train = 0.986  tune = 0.767  test = 0.831    06:50:34  04-01-2017\n",
      "After   20 epochs, accuracies are:  train = 0.975  tune = 0.750  test = 0.753    06:50:36  04-01-2017\n",
      "After   21 epochs, accuracies are:  train = 0.991  tune = 0.811* test = 0.803    06:50:38  04-01-2017\n",
      "After   22 epochs, accuracies are:  train = 0.989  tune = 0.811  test = 0.843    06:50:40  04-01-2017\n",
      "After   23 epochs, accuracies are:  train = 0.995  tune = 0.789  test = 0.798    06:50:41  04-01-2017\n",
      "After   24 epochs, accuracies are:  train = 0.991  tune = 0.817* test = 0.831    06:50:43  04-01-2017\n",
      "After   25 epochs, accuracies are:  train = 0.987  tune = 0.800  test = 0.803    06:50:45  04-01-2017\n",
      "After   26 epochs, accuracies are:  train = 0.960  tune = 0.761  test = 0.770    06:50:47  04-01-2017\n",
      "After   27 epochs, accuracies are:  train = 0.995  tune = 0.794  test = 0.826    06:50:49  04-01-2017\n",
      "After   28 epochs, accuracies are:  train = 0.993  tune = 0.822* test = 0.826    06:50:51  04-01-2017\n",
      "After   29 epochs, accuracies are:  train = 0.998  tune = 0.800  test = 0.831    06:50:52  04-01-2017\n",
      "After   30 epochs, accuracies are:  train = 0.991  tune = 0.789  test = 0.826    06:50:54  04-01-2017\n",
      "After   31 epochs, accuracies are:  train = 0.996  tune = 0.811  test = 0.820    06:50:56  04-01-2017\n",
      "After   32 epochs, accuracies are:  train = 0.998  tune = 0.789  test = 0.809    06:50:58  04-01-2017\n",
      "After   33 epochs, accuracies are:  train = 0.986  tune = 0.789  test = 0.798    06:50:59  04-01-2017\n",
      "After   34 epochs, accuracies are:  train = 0.978  tune = 0.778  test = 0.803    06:51:01  04-01-2017\n",
      "After   35 epochs, accuracies are:  train = 0.996  tune = 0.806  test = 0.803    06:51:03  04-01-2017\n",
      "After   36 epochs, accuracies are:  train = 0.996  tune = 0.839* test = 0.820    06:51:05  04-01-2017\n",
      "After   37 epochs, accuracies are:  train = 0.998  tune = 0.817  test = 0.798    06:51:07  04-01-2017\n",
      "After   38 epochs, accuracies are:  train = 0.995  tune = 0.800  test = 0.826    06:51:09  04-01-2017\n",
      "After   39 epochs, accuracies are:  train = 0.998  tune = 0.811  test = 0.815    06:51:11  04-01-2017\n",
      "After   40 epochs, accuracies are:  train = 0.996  tune = 0.806  test = 0.826    06:51:13  04-01-2017\n",
      "After   41 epochs, accuracies are:  train = 0.995  tune = 0.789  test = 0.787    06:51:15  04-01-2017\n",
      "After   42 epochs, accuracies are:  train = 0.998  tune = 0.817  test = 0.837    06:51:17  04-01-2017\n",
      "After   43 epochs, accuracies are:  train = 1.000  tune = 0.817  test = 0.815    06:51:19  04-01-2017\n",
      "After   44 epochs, accuracies are:  train = 0.993  tune = 0.811  test = 0.798    06:51:21  04-01-2017\n",
      "After   45 epochs, accuracies are:  train = 0.996  tune = 0.778  test = 0.803    06:51:23  04-01-2017\n",
      "After   46 epochs, accuracies are:  train = 1.000  tune = 0.817  test = 0.803    06:51:25  04-01-2017\n",
      "After   47 epochs, accuracies are:  train = 0.991  tune = 0.806  test = 0.815    06:51:27  04-01-2017\n",
      "After   48 epochs, accuracies are:  train = 0.998  tune = 0.794  test = 0.792    06:51:29  04-01-2017\n",
      "After   49 epochs, accuracies are:  train = 0.996  tune = 0.817  test = 0.792    06:51:32  04-01-2017\n",
      "After   50 epochs, accuracies are:  train = 0.995  tune = 0.794  test = 0.820    06:51:34  04-01-2017\n",
      "After   51 epochs, accuracies are:  train = 0.993  tune = 0.789  test = 0.815    06:51:36  04-01-2017\n",
      "After   52 epochs, accuracies are:  train = 0.998  tune = 0.800  test = 0.809    06:51:37  04-01-2017\n",
      "After   53 epochs, accuracies are:  train = 1.000  tune = 0.822  test = 0.831    06:51:39  04-01-2017\n",
      "After   54 epochs, accuracies are:  train = 0.996  tune = 0.811  test = 0.792    06:51:41  04-01-2017\n",
      "After   55 epochs, accuracies are:  train = 1.000  tune = 0.817  test = 0.831    06:51:43  04-01-2017\n",
      "After   56 epochs, accuracies are:  train = 0.998  tune = 0.811  test = 0.826    06:51:45  04-01-2017\n",
      "After   57 epochs, accuracies are:  train = 0.998  tune = 0.833  test = 0.837    06:51:47  04-01-2017\n",
      "After   58 epochs, accuracies are:  train = 0.998  tune = 0.800  test = 0.798    06:51:48  04-01-2017\n",
      "After   59 epochs, accuracies are:  train = 1.000  tune = 0.822  test = 0.815    06:51:50  04-01-2017\n",
      "After   60 epochs, accuracies are:  train = 1.000  tune = 0.822  test = 0.820    06:51:52  04-01-2017\n",
      "After   61 epochs, accuracies are:  train = 1.000  tune = 0.811  test = 0.826    06:51:54  04-01-2017\n",
      "After   62 epochs, accuracies are:  train = 0.989  tune = 0.778  test = 0.820    06:51:56  04-01-2017\n",
      "After   63 epochs, accuracies are:  train = 1.000  tune = 0.800  test = 0.843    06:51:58  04-01-2017\n",
      "After   64 epochs, accuracies are:  train = 0.998  tune = 0.794  test = 0.826    06:52:00  04-01-2017\n",
      "After   65 epochs, accuracies are:  train = 1.000  tune = 0.800  test = 0.815    06:52:01  04-01-2017\n",
      "After   66 epochs, accuracies are:  train = 0.998  tune = 0.800  test = 0.809    06:52:03  04-01-2017\n",
      "After   67 epochs, accuracies are:  train = 1.000  tune = 0.811  test = 0.815    06:52:05  04-01-2017\n",
      "After   68 epochs, accuracies are:  train = 0.998  tune = 0.806  test = 0.815    06:52:07  04-01-2017\n",
      "After   69 epochs, accuracies are:  train = 0.998  tune = 0.817  test = 0.809    06:52:09  04-01-2017\n",
      "After   70 epochs, accuracies are:  train = 0.996  tune = 0.800  test = 0.826    06:52:10  04-01-2017\n",
      "After   71 epochs, accuracies are:  train = 0.998  tune = 0.772  test = 0.809    06:52:12  04-01-2017\n",
      "After   72 epochs, accuracies are:  train = 0.986  tune = 0.772  test = 0.787    06:52:14  04-01-2017\n",
      "After   73 epochs, accuracies are:  train = 0.998  tune = 0.822  test = 0.803    06:52:16  04-01-2017\n",
      "After   74 epochs, accuracies are:  train = 1.000  tune = 0.794  test = 0.809    06:52:18  04-01-2017\n",
      "After   75 epochs, accuracies are:  train = 0.991  tune = 0.756  test = 0.809    06:52:20  04-01-2017\n",
      "After   76 epochs, accuracies are:  train = 0.998  tune = 0.839  test = 0.843    06:52:21  04-01-2017\n",
      "After   77 epochs, accuracies are:  train = 1.000  tune = 0.806  test = 0.815    06:52:23  04-01-2017\n",
      "After   78 epochs, accuracies are:  train = 0.996  tune = 0.800  test = 0.831    06:52:25  04-01-2017\n",
      "After   79 epochs, accuracies are:  train = 1.000  tune = 0.828  test = 0.809    06:52:27  04-01-2017\n",
      "After   80 epochs, accuracies are:  train = 1.000  tune = 0.833  test = 0.815    06:52:29  04-01-2017\n",
      "After   81 epochs, accuracies are:  train = 1.000  tune = 0.811  test = 0.815    06:52:31  04-01-2017\n",
      "After   82 epochs, accuracies are:  train = 1.000  tune = 0.800  test = 0.837    06:52:33  04-01-2017\n",
      "After   83 epochs, accuracies are:  train = 1.000  tune = 0.794  test = 0.798    06:52:35  04-01-2017\n",
      "After   84 epochs, accuracies are:  train = 0.996  tune = 0.828  test = 0.826    06:52:37  04-01-2017\n",
      "After   85 epochs, accuracies are:  train = 0.998  tune = 0.800  test = 0.837    06:52:39  04-01-2017\n",
      "After   86 epochs, accuracies are:  train = 0.996  tune = 0.794  test = 0.815    06:52:41  04-01-2017\n",
      "After   87 epochs, accuracies are:  train = 1.000  tune = 0.806  test = 0.848    06:52:43  04-01-2017\n",
      "After   88 epochs, accuracies are:  train = 0.996  tune = 0.828  test = 0.843    06:52:45  04-01-2017\n",
      "After   89 epochs, accuracies are:  train = 0.998  tune = 0.806  test = 0.837    06:52:46  04-01-2017\n",
      "After   90 epochs, accuracies are:  train = 0.998  tune = 0.783  test = 0.764    06:52:48  04-01-2017\n",
      "After   91 epochs, accuracies are:  train = 0.996  tune = 0.817  test = 0.815    06:52:50  04-01-2017\n",
      "After   92 epochs, accuracies are:  train = 0.996  tune = 0.789  test = 0.787    06:52:52  04-01-2017\n",
      "After   93 epochs, accuracies are:  train = 0.996  tune = 0.789  test = 0.820    06:52:54  04-01-2017\n",
      "After   94 epochs, accuracies are:  train = 1.000  tune = 0.817  test = 0.826    06:52:56  04-01-2017\n",
      "After   95 epochs, accuracies are:  train = 1.000  tune = 0.794  test = 0.848    06:52:58  04-01-2017\n",
      "After   96 epochs, accuracies are:  train = 1.000  tune = 0.822  test = 0.809    06:53:00  04-01-2017\n",
      "After   97 epochs, accuracies are:  train = 0.989  tune = 0.800  test = 0.815    06:53:02  04-01-2017\n",
      "After   98 epochs, accuracies are:  train = 1.000  tune = 0.811  test = 0.848    06:53:04  04-01-2017\n",
      "After   99 epochs, accuracies are:  train = 1.000  tune = 0.817  test = 0.826    06:53:05  04-01-2017\n",
      "After  100 epochs, accuracies are:  train = 0.998  tune = 0.811  test = 0.826    06:53:07  04-01-2017\n",
      "\n",
      "Final accuracy train = 0.998, tune = 0.811, test = 0.826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numberOfWeights = 0\n",
    "for tw in model.trainable_weights:\n",
    "    numberOfWeights += prod([dim.value for dim in tw.get_shape()])\n",
    "print()\n",
    "print(\"The model has {:,} trainable weights.\".format(numberOfWeights))\n",
    "print()\n",
    "\n",
    "optimizerToUse = Adam() \n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizerToUse, metrics = ['accuracy']) \n",
    "for i in range(epochsToRun):\n",
    "    model.fit(X_train, \n",
    "              y_onehot_train, \n",
    "              epochs     = 1, \n",
    "              batch_size = batch_size,\n",
    "              verbose    = 0,  shuffle    = True)\n",
    "              \n",
    "    acc_train = accuracy(model, X_train, y_train)\n",
    "    acc_tune  = accuracy(model, X_tune, y_tune)\n",
    "    acc_test  = accuracy(model, X_test, y_test)\n",
    "    \n",
    "    marker    = \" \"\n",
    "    if acc_tune > bestTuneSetAcc:\n",
    "        bestTuneSetEpoch     = i\n",
    "        bestTuneSetAcc       = acc_tune\n",
    "        testSetAccAtBestTune = acc_test\n",
    "        marker               = \"*\"\n",
    "        y_pred_test = model.predict_classes(X_test, verbose = 0)\n",
    "        confusionTestsetAtBestTuneset.fill(0)\n",
    "        for y_pred, y in zip(y_pred_test, y_test):\n",
    "            confusionTestsetAtBestTuneset[y, y_pred] += 1\n",
    "\n",
    "    print(\"After {:>4} epochs, accuracies are:  train = {:.3f}  tune = {:.3f}{} test = {:.3f}    {}\".format(i+1, acc_train, acc_tune, marker, acc_test, datetime.now().strftime('%H:%M:%S  %m-%d-%Y')))\n",
    "    \n",
    "# Done with training.\n",
    "print()\n",
    "print(\"Final accuracy train = {:.3f}, tune = {:.3f}, test = {:.3f}\".format(acc_train, acc_tune, acc_test))\n",
    "\n",
    "\n",
    "    \n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best testset accuracy at Epoch #36 = 0.820\n",
      "\n",
      "Testset confusionTestsetAtBestTuneset matrix chosen by early stopping (rows are true class, cols are predicted class)\n",
      "\n",
      "           |  airplanes  butterfly     flower      grand   starfish      watch\n",
      "------------------------------------------------------------------------------\n",
      "airplanes  |       39.0        0.0        1.0        0.0        0.0        1.0\n",
      "butterfly  |        2.0       10.0        1.0        0.0        3.0        2.0\n",
      "flower     |        0.0        1.0       31.0        1.0        3.0        1.0\n",
      "grand      |        1.0        1.0        1.0       16.0        0.0        0.0\n",
      "starfish   |        1.0        2.0        2.0        0.0        9.0        3.0\n",
      "watch      |        0.0        2.0        2.0        0.0        1.0       41.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Best testset accuracy at Epoch #{} = {:.3f}\".format(bestTuneSetEpoch+1, testSetAccAtBestTune))\n",
    "print()\n",
    "print(\"Testset confusionTestsetAtBestTuneset matrix chosen by early stopping (rows are true class, cols are predicted class)\")\n",
    "print()\n",
    "fmt = \" | {:>10} {:>10} {:>10} {:>10} {:>10} {:>10}\"\n",
    "print(\"{:10}\".format(\"\") + fmt.format(*LABELS))\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "\n",
    "for rowIndex in range(numberOfClasses):\n",
    "    print(\"{:10}\".format(LABELS[rowIndex]) + fmt.format(*confusionTestsetAtBestTuneset[rowIndex, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create a web page to view the errors.\n",
    "with open(join(IMG_DIR, \"errors.html\"), \"w\") as F:\n",
    "    F.write(\"<table> \\n\".format(LABELS[y_pred]))\n",
    "    for y_pred, y, filename in zip(y_pred_test, y_test, img_files_test): # See zip example above.\n",
    "        if y_pred != y:\n",
    "            img_file = join(\"testset\", basename(filename))\n",
    "            F.write(\"<tr> <td>I thought this was a {}</td>\\n\".format(LABELS[y_pred]))\n",
    "            F.write(\"<td> <img src='{}' style='border-color: red' border=5> </td>\\n\".format(img_file))\n",
    "            F.write(\"</tr>\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
